\documentclass[a4paper, 12pt]{article}
\usepackage{amsmath}
\usepackage{color}
\usepackage{dsfont}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[left=2cm, right=2cm, bottom=3cm, top=2cm]{geometry}
\usepackage{microtype}
\usepackage{natbib}
\usepackage{pdflscape}


\definecolor{orange}{rgb}{1, 0.5, 0}
\definecolor{green}{rgb}{0, 0.5, 0}

\newcommand{\hypers}{\boldsymbol{\alpha}}
\newcommand{\params}{\boldsymbol{\theta}}
\newcommand{\data}{\boldsymbol{d}}
\newcommand{\info}{I}
\newcommand{\x}{x}
\newcommand{\todo}{\color{orange} \bf}


\title{Crystals}
\author{Brendon J. Brewer}
\date{}

\begin{document}
\maketitle

%\abstract{\noindent Abstract}

% Need this after the abstract
\setlength{\parindent}{0pt}
\setlength{\parskip}{8pt}

\section{Bayesian inference}
In the Bayesian framework, probability distributions are used to model
states of uncertainty about the values of unknown quantities.
Typically, one starts with the ``prior distribution''
for unknown quantities (`parameters') $\params$, written $p(\params | \info)$
(the probability distribution for $\params$ {\em given} prior information
$\info$). This is supplemented with $p(\data | \params, \info)$,
which describes the uncertainty about the data which we {\em would} have,
if we knew the parameters (and the prior information), as a function of
the parameters.

The
product of these is the joint prior
\begin{align}
p(\params, \data | \info) &= p(\params | \info)p(\data | \params, \info).
\end{align}
Once a specific observed dataset $\data_o$ is known, knowledge about
$\params$ is updated from the prior to the posterior
\begin{align}
p(\params | \data_0, \info) &\propto
    p(\params | \info)p(\data_o | \params, \info).
\end{align}
which takes the specific data $\data_0$ into account.

\section{The model curve}
The algorithm fits the data with a model curve
$f(\x)$, defined between $\x=\x_{\rm min}$ and $\x=\x_{\rm max}$,
which is assumed to be a sum of the following components:
\begin{enumerate}
\item A background component, described by parameters $\params_{\rm bg}$
\item A wide component, described by parameters $\params_{\rm wide}$
\item Narrow spikes, described by parameters $\params_{\rm narrow}$
\end{enumerate}

The total model function $f_{\rm tot}(x)$ is therefore
\begin{align}
f_{\rm tot}(\x) &= f_{\rm bg}(\x; \params_{\rm bg})
       + f_{\rm wide}(\x; \params_{\rm wide})
       + f_{\rm narrow}(\x; \params_{\rm narrow})
\end{align}
and the crystallinity is defined as the proportion of the area in the
wide and narrow components which is accounted for by the wide component:
\begin{align}
C &= \frac{\int_{\x_{\rm min}}^{\x_{\rm max}}
            f_{\rm wide}(\x; \params_{\rm wide}) \, d\x}
          {\int_{\x_{\rm min}}^{\x_{\rm max}}
            \left[f_{\rm wide}(\x; \params_{\rm wide})
            + f_{\rm narrow}(\x; \params_{\rm narrow}) \right] \, d\x}
\end{align}

We compute the posterior distribution for the unknown parameters of the
components, using \citep{dnest4} to generate samples from that posterior
distribution. The output is a collection of plausible values of the
parameters which can be used to approximate posterior probabilities.
For example, the probability some parameter $\theta$ is greater than 3.4
is approximately the proportion of the posterior samples that have
$\theta > 3.4$.

From each sample,
it is possible to compute the crystallinity, making it straightforward to
calculate the marginal posterior distribution of the crystallinity, describing
the remaining uncertainty about its value in the light of the data.

In the following subsections, I describe the specific parameterisations of the
three parts of the model curve.

\subsection{The background component}
The background component is assumed to be piecewise linear
{\todo between $\x=\x_{\rm min}$ and $\x=10$, between $\x=10$ and $\x=40$,
and between $\x=40$ and $\x=\x_{\rm max}$}.
We parameterise the background component using
five parameters. Firstly, there is a mean level $b$, which sets the
typical amplitude of the background component. There are also four parameters
$n_1, ..., n_4$, which set the positions of four control points:
\begin{align}
\left(\x_{\rm min}, be^{n_1}\right) \nonumber\\
\left(10, be^{n_2}\right) \nonumber\\
\left(40, be^{n_3}\right) \nonumber\\
\left(\x_{\rm max}, be^{n_4}\right) \nonumber
\end{align}
The value of the background component at any other point is found by
linear interpolation. Figure~\ref{fig:background} shows three example
background curves generated from this parameterisation, with typical
values of the parameters.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/background.pdf}
\caption{Three example functions showing possible shapes of the
background component.\label{fig:background}}
\end{figure}

\subsection{The narrow spikes}
I assumed that there is some number $N_{\rm narrow}$ of narrow spikes,
with central positions $X_1, X_2, ..., X_{N, \rm narrow}$, amplitudes
$A_1, A_2, ..., A_{N, \rm narrow}$, and widths
$W_1, W_2, ..., W_{N, \rm narrow}$. The total shape contributed by the
narrow spikes is a sum of $N_{\rm narrow}$ gaussians:
\begin{align}
f_{\rm narrow}(\x; \params_{\rm narrow}) &=
    \sum_{i=1}^{N_{\rm narrow}} A_i
                        \exp\left[-\frac{1}{2W_i^2}\left(x - X_i\right)^2\right]
\end{align}

\subsection{The wide `spikes'}

\subsection{Prior probability distributions}

The joint prior distribution for the hyperparameters, parameters, and data,
is written $p(\hypers, \params, \data | \info)$, and is usually factorised
in this way:
\begin{align}
p(\hypers, \params, \data | \info) &=
    p(\hypers | \info)p(\params | \hypers, \info)
    p(\data | \params, \hypers, \info)\\
    &= p(\hypers | \info)p(\params | \hypers, \info)
    p(\data | \params, \info)
\end{align}
where the first step is true in general by the product rule, and the second
step assumes that knowing the parameters would make the hyperparameters
irrelevant when predicting what data would be observed.

All of the assumptions are given in Table~\ref{tab:priors}.

\begin{landscape}

\begin{table}
\footnotesize
\centering
\begin{tabular}{|lll|}
\hline
{\bf Quantity}      &   {\bf Meaning}   &  {\bf Prior distribution}\\
\hline
{\em Prior information}&&\\
\hline
$n$ & Number of measurements & given\\
$\{\x_1, \x_2, ..., \x_n\}$  & $\x$-values of measurements & given \\
\hline
{\em Hyperparameters} & &\\
$N_{\rm narrow}$   &   Number of narrow spikes    &  $\propto 1/(N_{\rm narrow}+1)$, $N_{\rm narrow} \in \{0, 1, ..., 300\}$ \\
$N_{\rm wide}$   &   Number of wide spikes    &  $\propto 1/(N_{\rm wide}+1)$,
$N_{\rm wide} \in \{0, 1, ..., 300\}$ \\
$a_{\ln A, \rm narrow}$ & Typical log-amplitude of narrow spikes & Laplace(0, 5)\\
$a_{\ln A, \rm wide}$ & Typical log-amplitude of wide spikes & Laplace(0, 5)\\
$b_{\ln A, \rm narrow}$ & Diversity of log-amplitude of narrow spikes & Uniform(0, 5)\\
$b_{\ln A, \rm wide}$ & Diversity of log-amplitude of wide spikes & Uniform(0, 5)\\
$a_{\ln W, \rm narrow}$ & Typical log-width of narrow spikes & LogUniform$(10^{-3}x_{\rm range}, 0.05x_{\rm range})$\\
$a_{\ln W, \rm wide}$ & Typical log-width of wide spikes & LogUniform$(0.05x_{\rm range}, x_{\rm range})$\\
$b_{\ln W, \rm narrow}$ & Diversity of log-width of narrow spikes & Uniform(0, 0.1)\\
$b_{\ln W, \rm wide}$ & Diversity of log-width of wide spikes & Uniform(0, 0.2)\\
\hline
{\em Background parameters}&&\\
$b$       & Mean background level       & $\ln b \sim $ Laplace$(0, 5)$\\
$\{n_1, ..., n_4\}$  & Background deviations & iid Normal$(0,1)$\\
\hline
{\em Narrow spike parameters}&&\\
$X_{i, \rm narrow}$ & Positions of narrow spikes &
                            Uniform$(x_{\rm min}, x_{\rm max})$ \\
$A_{i, \rm narrow}$ & Amplitudes of narrow spikes &
 $\ln A_{i, \rm narrow} \sim \textnormal{Laplace}\left(a_{\ln A, \rm narrow}, b_{\ln A, \rm narrow}\right)$ \\
$W_{i, \rm narrow}$ & Widths of narrow spikes &
 $\ln W_{i, \rm narrow} \sim \textnormal{Laplace}\left(a_{\ln W, \rm narrow}, b_{\ln W, \rm narrow}\right)$ \\
\hline
{\em Wide spike parameters}&&\\
$X_{i, \rm wide}$ & Positions of wide spikes &
          Uniform$(x_{\rm min}+0.3x_{\rm range}, x_{\rm max}-0.3x_{\rm range})$ \\
$A_{i, \rm wide}$ & Amplitudes of wide spikes &
 $\ln A_{i, \rm wide} \sim \textnormal{Laplace}\left(a_{\ln A, \rm wide}, b_{\ln A, \rm wide}\right)$ \\
$W_{i, \rm wide}$ & Widths of wide spikes &
 $\ln W_{i, \rm wide} \sim \textnormal{Laplace}\left(a_{\ln W, \rm wide}, b_{\ln W, \rm wide}\right)$ \\
\hline
{\em Noise parameters}&&\\
$\sigma_0$ &    Constant noise level  &   $\ln \sigma_0 \sim \textnormal{Laplace}(0,5)$\\
$\sigma_1$ &    Noise proportionality   &  $\ln \sigma_1 \sim \textnormal{Laplace}(0,5)$ \\
$\nu$     &   Shape parameter for residuals   &   LogUniform$(1, 1000)$\\
\hline
{\em Data}&&\\
\hline
$\{y_1, y_2, ..., y_n\}$  &   Measurements    & iid Student-$t(f(x_i; \params), ,\nu)$\\
\hline
\end{tabular}
\caption{\label{tab:priors}}
\end{table}

\end{landscape}

The Laplace, or biexponential, distribution with location parameter
(central position) $a$ and scale parameter (width) $b$ has probability
density given by
\begin{align}
p(x | a, b) &= \frac{1}{2b}\exp\left[-\frac{|x - a|}{b}\right].
\end{align}
We used a Laplace distribution for informative priors, rather than
a more conventional normal distribution, because it assigns higher
prior probability to values far from the center, and can be computed conveniently, i.e., no special functions such as {\tt erf} are needed
to compute the cumulative distribution function.


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}

